{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr7WzgEilxaSo8xzgVSO/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girikanchan/colabassignment/blob/main/KanchanGiri_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script defines several functions:\n",
        "\n",
        "* get_latest_version(): Scrapes the Ubuntu Security repository to retrieve the latest version of Chromium browser for Ubuntu 18.04.\n",
        "\n",
        "* download(latest_version, quiet): Downloads and installs Chromium browser and its dependencies for Ubuntu 20.04 using the retrieved latest version. It also supports a quiet mode to suppress verbosity during installation.\n",
        "\n",
        "* check_chromium_installation(): Checks if Chromium browser is successfully installed by attempting to run it.\n",
        "\n",
        "* install_selenium_package(quiet): Installs the Selenium package via pip. It also supports a quiet mode to suppress verbosity during installation.\n",
        "\n",
        "* main(quiet): The main function orchestrates the entire process by calling the above functions in sequence. It first gets the latest Chromium version, downloads and installs Chromium and its dependencies, checks the installation, and finally installs Selenium.\n",
        "\n",
        "The script can be executed as a standalone Python script, and you can set the quiet variable to control the verbosity of downloads and installations. When quiet is set to True, it will run in a quieter mode."
      ],
      "metadata": {
        "id": "0UuNm3-_krbo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1QYkj_rXgwsX"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import requests\n",
        "\n",
        "# The deb files we need to install\n",
        "deb_files_startstwith = [\n",
        "    \"chromium-codecs-ffmpeg-extra_\",\n",
        "    \"chromium-codecs-ffmpeg_\",\n",
        "    \"chromium-browser_\",\n",
        "    \"chromium-chromedriver_\"\n",
        "]\n",
        "\n",
        "def get_latest_version() -> str:\n",
        "    # A request to security.ubuntu.com for getting latest version of chromium-browser\n",
        "    # e.g. \"112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\"\n",
        "    url = \"http://security.ubuntu.com/ubuntu/pool/universe/c/chromium-browser/\"\n",
        "    r = requests.get(url)\n",
        "    if r.status_code != 200:\n",
        "        raise Exception(\"status_code code not 200!\")\n",
        "    text = r.text\n",
        "\n",
        "    # Find latest version\n",
        "    pattern = '<a\\shref=\"chromium\\-browser_([^\"]+.ubuntu0\\.18\\.04\\.1_amd64\\.deb)'\n",
        "    latest_version_search = re.search(pattern, text)\n",
        "    if latest_version_search:\n",
        "        latest_version = latest_version_search.group(1)\n",
        "    else:\n",
        "        raise Exception(\"Can not find latest version!\")\n",
        "    return latest_version\n",
        "\n",
        "def download(latest_version: str, quiet: bool):\n",
        "    deb_files = []\n",
        "    for deb_file in deb_files_startstwith:\n",
        "        deb_files.append(deb_file + latest_version)\n",
        "\n",
        "    for deb_file in deb_files:\n",
        "        url = f\"http://security.ubuntu.com/ubuntu/pool/universe/c/chromium-browser/{deb_file}\"\n",
        "\n",
        "        # Download deb file\n",
        "        if quiet:\n",
        "            command = f\"wget -q -O /content/{deb_file} {url}\"\n",
        "        else:\n",
        "            command = f\"wget -O /content/{deb_file} {url}\"\n",
        "        print(f\"Downloading: {deb_file}\")\n",
        "        # os.system(command)\n",
        "        !$command\n",
        "\n",
        "        # Install deb file\n",
        "        if quiet:\n",
        "            command = f\"apt-get install /content/{deb_file} >> apt.log\"\n",
        "        else:\n",
        "            command = f\"apt-get install /content/{deb_file}\"\n",
        "        print(f\"Installing: {deb_file}\\n\")\n",
        "        # os.system(command)\n",
        "        !$command\n",
        "\n",
        "        # Delete deb file from disk\n",
        "        os.remove(f\"/content/{deb_file}\")\n",
        "\n",
        "def check_chromium_installation():\n",
        "    try:\n",
        "        subprocess.call([\"chromium-browser\"])\n",
        "        print(\"Chromium installation successfull.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Chromium Installation Failed!\")\n",
        "\n",
        "def install_selenium_package(quiet: bool):\n",
        "    if quiet:\n",
        "        !pip install selenium -qq >> pip.log\n",
        "    else:\n",
        "        !pip install selenium\n",
        "\n",
        "def main(quiet: bool):\n",
        "    # Get the latest version of chromium-browser for ubuntu 18.04\n",
        "    latest_version = get_latest_version()\n",
        "    # Download and install chromium-browser for ubuntu 20.04\n",
        "    download(latest_version, quiet)\n",
        "    # Check if installation succesfull\n",
        "    check_chromium_installation()\n",
        "    # Finally install selenium package\n",
        "    install_selenium_package(quiet)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    quiet = True # verboseness of wget and apt\n",
        "    main(quiet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fam8gi8M6Kfw",
        "outputId": "b5bad5ef-08ef-4253-edc4-ee16f8c36db5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: chromium-codecs-ffmpeg-extra_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-codecs-ffmpeg-extra_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Downloading: chromium-codecs-ffmpeg_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-codecs-ffmpeg_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Downloading: chromium-browser_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-browser_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Downloading: chromium-chromedriver_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "Installing: chromium-chromedriver_112.0.5615.49-0ubuntu0.18.04.1_amd64.deb\n",
            "\n",
            "Chromium installation successfull.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install chromium, its driver, and selenium\n",
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxr9JNZ568IC",
        "outputId": "8a052723-ec62-460c-f135-be8e8a2fc1fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connected to cloud.r-p\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [2 InRelease 15.6 kB/119 kB 13%] [Connecting to security.ubuntu.com (185.125\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "\u001b[33m\r0% [4 InRelease 11.4 kB/109 kB 11%] [Waiting for headers] [Connecting to ppa.la\u001b[0m\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,155 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,282 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,259 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,134 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,013 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [996 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,197 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,127 kB]\n",
            "Fetched 10.5 MB in 3s (3,316 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "27 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libxtst6\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 libudev1 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor libfuse3-3 liblzo2-2 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  chromium-browser chromium-chromedriver libudev1\n",
            "3 upgraded, 7 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 26.4 MB of archives.\n",
            "After this operation, 178 MB disk space will be freed.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.2 [595 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.10 [78.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.10 [1,557 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.58+22.04.1 [23.8 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.3 [2,908 B]\n",
            "Fetched 26.4 MB in 0s (73.9 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 120973 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.2_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.2) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.10_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.10) over (249.11-0ubuntu3.9) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.10) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 121180 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.10_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.10) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.58+22.04.1_amd64.deb ...\n",
            "Unpacking snapd (2.58+22.04.1) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.2) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.10) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.58+22.04.1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.aa-prompt-listener.service → /lib/systemd/system/snapd.aa-prompt-listener.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "(Reading database ... 121413 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "=> Connecting the password-manager-service interface (LP: #1836616)\n",
            "error: cannot communicate with server: Post \"http://localhost/v2/interfaces\": dial unix /run/snapd.socket: connect: no such file or directory\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) over (112.0.5615.49-0ubuntu0.18.04.1) ...\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m unable to delete old directory '/etc/chromium-browser/customizations': Directory not empty\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m unable to delete old directory '/etc/chromium-browser': Directory not empty\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) over (112.0.5615.49-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.3_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.3) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.3) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Removing obsolete conffile /etc/chromium-browser/default ...\n",
            "Removing obsolete conffile /etc/chromium-browser/customizations/00-example ...\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.10) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.12.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.4)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.22.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.10.4)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.3)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install webdriver_manager\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdRzmD-sQFbY",
        "outputId": "cc1ba7bb-37fa-47a3-a899-18f165396c4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.0-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.31.0)\n",
            "Collecting python-dotenv (from webdriver_manager)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (2023.7.22)\n",
            "Installing collected packages: python-dotenv, webdriver_manager\n",
            "Successfully installed python-dotenv-1.0.0 webdriver_manager-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.common import NoSuchElementException\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "\n",
        "class GoogleMapScraper:\n",
        "    def __init__(self):\n",
        "        self.output_file_name = \"google_map_business_data.csv\"\n",
        "        self.headless = False\n",
        "        self.unique_check = []\n",
        "        self.driver = self.config_driver()  # Initialize the driver here\n",
        "\n",
        "    def config_driver(self):\n",
        "        options = webdriver.ChromeOptions()\n",
        "        options.add_argument('--headless')\n",
        "        options.add_argument('--no-sandbox')\n",
        "        options.add_argument('--disable-dev-shm-usage')\n",
        "        driver = webdriver.Chrome(options=options)\n",
        "        return driver\n",
        "\n",
        "    def save_data(self, data):\n",
        "        header = ['id', 'company_name', 'rating', 'reviews_count', 'address', 'category', 'phone', 'website']\n",
        "        with open(self.output_file_name, 'a', newline='', encoding=\"utf-8\") as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            if data[0] == 1:\n",
        "                writer.writerow(header)\n",
        "            writer.writerow(data)\n",
        "\n",
        "\n",
        "    def parse_contact(self, business):\n",
        "        try:\n",
        "            contact = business.find_elements(By.CLASS_NAME, \"W4Efsd\")[3].text.split(\"·\")[-1].strip()\n",
        "        except:\n",
        "            contact = \"\"\n",
        "\n",
        "        if \"+1\" not in contact:\n",
        "            try:\n",
        "                contact = business.find_elements(By.CLASS_NAME, \"W4Efsd\")[4].text.split(\"·\")[-1].strip()\n",
        "            except:\n",
        "                contact = \"\"\n",
        "\n",
        "        return contact\n",
        "\n",
        "\n",
        "    def parse_rating_and_review_count(self, business):\n",
        "        try:\n",
        "            reviews_block = business.find_element(By.CLASS_NAME, 'AJB7ye').text.split(\"(\")\n",
        "            rating = reviews_block[0].strip()\n",
        "            reviews_count = reviews_block[1].split(\")\")[0].strip()\n",
        "        except:\n",
        "            rating = \"\"\n",
        "            reviews_count = \"\"\n",
        "\n",
        "        return rating, reviews_count\n",
        "\n",
        "\n",
        "    def parse_address_and_category(self, business):\n",
        "        try:\n",
        "            address_block = business.find_elements(By.CLASS_NAME, \"W4Efsd\")[2].text.split(\"·\")\n",
        "            if len(address_block) >= 2:\n",
        "                address = address_block[1].strip()\n",
        "                category = address_block[0].strip()\n",
        "            elif len(address_block) == 1:\n",
        "                address = \"\"\n",
        "                category = address_block[0]\n",
        "        except:\n",
        "            address = \"\"\n",
        "            category = \"\"\n",
        "\n",
        "        return address, category\n",
        "\n",
        "\n",
        "    def get_business_info(self):\n",
        "        time.sleep(2)\n",
        "        for business in self.driver.find_elements(By.CLASS_NAME, 'THOPZb'):\n",
        "            name = business.find_element(By.CLASS_NAME, 'fontHeadlineSmall').text\n",
        "            rating, reviews_count = self.parse_rating_and_review_count(business)\n",
        "            address, category = self.parse_address_and_category(business)\n",
        "            contact = self.parse_contact(business)\n",
        "            try:\n",
        "                website = business.find_element(By.CLASS_NAME, \"lcr4fd\").get_attribute(\"href\")\n",
        "            except NoSuchElementException:\n",
        "                website = \"\"\n",
        "\n",
        "            unique_id = \"\".join([name, rating, reviews_count, address, category, contact, website])\n",
        "            if unique_id not in self.unique_check:\n",
        "                data = [name, rating, reviews_count, address, category, contact, website]\n",
        "                self.save_data(data)\n",
        "                self.unique_check.append(unique_id)\n",
        "\n",
        "\n",
        "\n",
        "    def load_companies(self, url):\n",
        "        print(\"Getting business info\", url)\n",
        "        self.driver.get(url)\n",
        "        time.sleep(5)\n",
        "        panel_xpath = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]'\n",
        "        panel_xpath = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]'\n",
        "        scrollable_div = self.driver.find_element(By.XPATH, panel_xpath)\n",
        "        # scrolling\n",
        "        flag = True\n",
        "        i = 0\n",
        "        while flag:\n",
        "            print(f\"Scrolling to page {i + 2}\")\n",
        "            self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
        "            time.sleep(2)\n",
        "\n",
        "            if \"You've reached the end of the list.\" in self.driver.page_source:\n",
        "                flag = False\n",
        "\n",
        "            self.get_business_info()\n",
        "            i += 1\n",
        "\n",
        "\n",
        "# Take input from the user for location and industry\n",
        "location = input(\"Enter the location: \")\n",
        "industry = input(\"Enter the industry: \")\n",
        "\n",
        "\n",
        "# Replace spaces with '+' in the location\n",
        "location = location.replace(\" \", \"+\")\n",
        "\n",
        "# Replace spaces with '+' in the industry\n",
        "industry = industry.replace(\" \", \"+\")\n",
        "\n",
        "# Generate the URL using f-strings\n",
        "url = f\"https://www.google.com/maps/search/{location}+{industry}/\"\n",
        "\n",
        "# Add the generated URL to your URLs list\n",
        "urls = [url]\n",
        "\n",
        "\n",
        "business_scraper = GoogleMapScraper()\n",
        "business_scraper.config_driver()\n",
        "for url in urls:\n",
        "    business_scraper.load_companies(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-McCqLnQAGd",
        "outputId": "0b5a4d90-e8a2-473a-fa46-5c11433cec75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the location: indore\n",
            "Enter the industry: apna sweets\n",
            "Getting business info https://www.google.com/maps/search/indore+apna+sweets/\n",
            "Scrolling to page 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Description\n",
        "The script uses the Selenium library to automate interactions with the Google Maps website. Here's a breakdown of the script along with some documentation:\n",
        "\n",
        "Purpose of the Script:\n",
        "\n",
        "The script is designed to scrape business information (such as company name, rating, reviews count, address, category, phone, and website) from Google Maps based on user-defined location and industry.\n",
        "\n",
        "Dependencies:\n",
        "* csv: Used for CSV file handling.\n",
        "* time: Used for adding delays between web interactions.\n",
        "* selenium: A web automation library for controlling a web browser through the program.\n",
        "* webdriver_manager.chrome: Used for managing the Chrome WebDriver.\n",
        "\n",
        "Class GoogleMapScraper:\n",
        "\n",
        "This class represents the Google Maps scraper. It contains methods for configuring the web driver, saving data to a CSV file, and parsing various pieces of information from business listings.\n",
        "\n",
        "Methods:\n",
        "\n",
        "* __init__(self): Initializes the scraper with default settings, creates a list to check for unique data, and configures the web driver.\n",
        "\n",
        "* config_driver(self): Configures the Chrome WebDriver with specific options (headless, no sandbox, and no shared memory).\n",
        "\n",
        "* save_data(self, data): Appends data to the CSV file. It first writes the header row if the file is empty.\n",
        "\n",
        "* parse_contact(self, business): Parses the contact information from a business listing.\n",
        "\n",
        "* parse_rating_and_review_count(self, business): Parses the rating and review count from a business listing.\n",
        "\n",
        "* parse_address_and_category(self, business): Parses the address, category, operating hours, and phone number from a business listing.\n",
        "\n",
        "* get_business_info(self): Scrapes business information from the current page of Google Maps listings.\n",
        "\n",
        "* load_companies(self, url): Loads Google Maps listings for a given URL, scrolls through the listings, and calls get_business_info() to scrape data.\n",
        "\n",
        "\n",
        "Input:\n",
        "\n",
        "The script takes user input for location and industry.\n",
        "\n",
        "* location: The geographical location where you want to search for businesses.\n",
        "* industry: The industry or category of businesses you want to search for.\n",
        "\n",
        "Usage:\n",
        "* User inputs the location and industry.\n",
        "* The script generates a Google Maps URL for the specified location and industry.\n",
        "* The GoogleMapScraper object is created.\n",
        "* The load_companies() method is called with the generated URL, which initiates the scraping process.\n",
        "\n",
        "\n",
        "Note:\n",
        "* The script performs scrolling to load more business listings dynamically.\n",
        "* It checks for unique business data to avoid duplicates in the CSV file.\n",
        "* It can be modified to handle multiple URLs if you want to scrape data from multiple search results pages."
      ],
      "metadata": {
        "id": "RFez-FtAiPIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.common import NoSuchElementException\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "\n",
        "class GoogleMapScraper:\n",
        "    def __init__(self):\n",
        "        self.output_file_name = \"google_map_business_data.csv\"\n",
        "        self.headless = False\n",
        "        self.unique_check = []\n",
        "        self.driver = self.config_driver()  # Initialize the driver here\n",
        "\n",
        "    def config_driver(self):\n",
        "        options = webdriver.ChromeOptions()\n",
        "        options.add_argument('--headless')\n",
        "        options.add_argument('--no-sandbox')\n",
        "        options.add_argument('--disable-dev-shm-usage')\n",
        "        driver = webdriver.Chrome(options=options)\n",
        "        return driver\n",
        "\n",
        "    def save_data(self, data):\n",
        "        header = ['id', 'company_name', 'rating', 'reviews_count', 'address', 'category', 'phone', 'website']\n",
        "        with open(self.output_file_name, 'a', newline='', encoding=\"utf-8\") as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            if data[0] == 1:\n",
        "                writer.writerow(header)\n",
        "            writer.writerow(data)\n",
        "\n",
        "\n",
        "    def parse_contact(self, business):\n",
        "        try:\n",
        "            contact = business.find_elements(By.CLASS_NAME, \"W4Efsd\")[3].text.split(\"·\")[-1].strip()\n",
        "        except:\n",
        "            contact = \"\"\n",
        "\n",
        "        if \"+1\" not in contact:\n",
        "            try:\n",
        "                contact = business.find_elements(By.CLASS_NAME, \"W4Efsd\")[4].text.split(\"·\")[-1].strip()\n",
        "            except:\n",
        "                contact = \"\"\n",
        "\n",
        "        return contact\n",
        "\n",
        "\n",
        "    def parse_rating_and_review_count(self, business):\n",
        "        try:\n",
        "            reviews_block = business.find_element(By.CLASS_NAME, 'AJB7ye').text.split(\"(\")\n",
        "            rating = reviews_block[0].strip()\n",
        "            reviews_count = reviews_block[1].split(\")\")[0].strip()\n",
        "        except:\n",
        "            rating = \"\"\n",
        "            reviews_count = \"\"\n",
        "\n",
        "        return rating, reviews_count\n",
        "\n",
        "    def parse_address_and_category(self, business):\n",
        "      try:\n",
        "        address_block = business.find_elements(By.CLASS_NAME, \"W4Efsd\")[2].text.split(\"·\")\n",
        "        print(address_block)\n",
        "        if len(address_block) >= 2:\n",
        "            category = address_block[0].strip()\n",
        "            address_info = address_block[1].strip().split(\"·\")\n",
        "            if len(address_info) == 2:\n",
        "                operating_hours = address_info[0].strip()\n",
        "                phone_number = address_info[1].strip()\n",
        "            elif len(address_info) == 1:\n",
        "                operating_hours = address_info[0].strip()\n",
        "                phone_number = \"\"\n",
        "        elif len(address_block) == 1:\n",
        "          address_info = \"\"\n",
        "          category = address_block[0]\n",
        "          operating_hours = \"\"\n",
        "          phone_number = \"\"\n",
        "      except:\n",
        "        category = \"\"\n",
        "        operating_hours = \"\"\n",
        "        phone_number = \"\"\n",
        "        address_info = \"\"\n",
        "\n",
        "      return address_info,category, operating_hours, phone_number\n",
        "\n",
        "    def get_business_info(self):\n",
        "        time.sleep(2)\n",
        "        for business in self.driver.find_elements(By.CLASS_NAME, 'THOPZb'):\n",
        "            name = business.find_element(By.CLASS_NAME, 'fontHeadlineSmall').text\n",
        "            rating, reviews_count = self.parse_rating_and_review_count(business)\n",
        "            address_info, category, operating_hours, phone_number = self.parse_address_and_category(business)\n",
        "            contact = self.parse_contact(business)\n",
        "            try:\n",
        "                website = business.find_element(By.CLASS_NAME, \"lcr4fd\").get_attribute(\"href\")\n",
        "            except NoSuchElementException:\n",
        "                website = \"\"\n",
        "\n",
        "            unique_id = \"\".join([name, rating, reviews_count, category, operating_hours, phone_number, contact, website])\n",
        "            if unique_id not in self.unique_check:\n",
        "              data = [name, rating, reviews_count, category, operating_hours, phone_number, contact, website]\n",
        "              self.save_data(data)\n",
        "              self.unique_check.append(unique_id)\n",
        "\n",
        "\n",
        "\n",
        "    def load_companies(self, url):\n",
        "        print(\"Getting business info\", url)\n",
        "        self.driver.get(url)\n",
        "        time.sleep(5)\n",
        "        panel_xpath = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]'\n",
        "        panel_xpath = '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]'\n",
        "        scrollable_div = self.driver.find_element(By.XPATH, panel_xpath)\n",
        "        # scrolling\n",
        "        flag = True\n",
        "        i = 0\n",
        "        while flag:\n",
        "            print(f\"Scrolling to page {i + 2}\")\n",
        "            self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
        "            time.sleep(2)\n",
        "\n",
        "            if \"You've reached the end of the list.\" in self.driver.page_source:\n",
        "                flag = False\n",
        "\n",
        "            self.get_business_info()\n",
        "            i += 1\n",
        "\n",
        "\n",
        "# Take input from the user for location and industry\n",
        "location = input(\"Enter the location: \")\n",
        "industry = input(\"Enter the industry: \")\n",
        "\n",
        "\n",
        "# Replace spaces with '+' in the location\n",
        "location = location.replace(\" \", \"+\")\n",
        "\n",
        "# Replace spaces with '+' in the industry\n",
        "industry = industry.replace(\" \", \"+\")\n",
        "\n",
        "# Generate the URL using f-strings\n",
        "url = f\"https://www.google.com/maps/search/{location}+{industry}/\"\n",
        "\n",
        "# Add the generated URL to your URLs list\n",
        "urls = [url]\n",
        "\n",
        "\n",
        "business_scraper = GoogleMapScraper()\n",
        "business_scraper.config_driver()\n",
        "for url in urls:\n",
        "    business_scraper.load_companies(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGXewkpdNnbG",
        "outputId": "b4115528-1ae7-4f64-fc7b-f39abc0ffd68"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the location: indore\n",
            "Enter the industry: hospital\n",
            "Getting business info https://www.google.com/maps/search/indore+hospital/\n",
            "Scrolling to page 2\n",
            "Scrolling to page 3\n",
            "Scrolling to page 4\n",
            "Scrolling to page 5\n",
            "Scrolling to page 6\n",
            "Scrolling to page 7\n",
            "Scrolling to page 8\n",
            "Scrolling to page 9\n",
            "Scrolling to page 10\n",
            "Scrolling to page 11\n",
            "Scrolling to page 12\n",
            "Scrolling to page 13\n",
            "Scrolling to page 14\n",
            "Scrolling to page 15\n",
            "Scrolling to page 16\n",
            "Scrolling to page 17\n",
            "Scrolling to page 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries\n",
        "Import the required libraries for working with CSV files, sending emails, and sending SMS messages using Twilio.\n",
        "python\n",
        "Copy code\n",
        "# Define email server settings\n",
        "\n",
        "Set the email address and password of the sender's Gmail account. Make sure to replace 'Generated_password' with the actual password.\n",
        "\n",
        "# Define Twilio credentials\n",
        "\n",
        "Set your Twilio account SID, authentication token, and the Twilio phone number from which you want to send SMS messages.\n",
        "\n",
        "# Open and read the CSV file\n",
        "with open('google_map_business_data.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    \n",
        "    # Skip the header row if it exists\n",
        "    next(reader, None)\n",
        "    \n",
        "    for row in reader:\n",
        "        name, rating, bed_count, category, address, phone_number, email, website = row\n",
        "Open and read the CSV file named 'google_map_business_data.csv'. It assumes that the CSV file has columns in the order: name, rating, bed_count, category, address, phone_number, email, and website. It also skips the header row using next(reader, None).\n",
        "\n",
        "        # Send email\n",
        "        subject = f'Information about {name}'\n",
        "        message = f'Rating: {rating}\\nBed Count: {bed_count}\\nCategory: {category}\\nAddress: {address}\\nWebsite: {website}'\n",
        "        msg = MIMEText(message)\n",
        "        msg['Subject'] = subject\n",
        "        msg['From'] = email_address\n",
        "        msg['To'] = email\n",
        "Prepare the email message. It sets the subject, message body, and sender/recipient addresses.\n",
        "\n",
        "        try:\n",
        "            # Connect to Gmail's SMTP server\n",
        "            server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "            server.starttls()\n",
        "            server.login(email_address, email_password)\n",
        "\n",
        "            # Send the email\n",
        "            server.sendmail(email_address, email, msg.as_string())\n",
        "            server.quit()\n",
        "\n",
        "            print(f\"Email sent to {name} at {email}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error sending email to {name}: {str(e)}\")\n",
        "Try to send the email using Gmail's SMTP server. If successful, it prints a confirmation message; otherwise, it prints an error message.\n",
        "\n",
        "        # Send SMS\n",
        "        try:\n",
        "            client = Client(twilio_account_sid, twilio_auth_token)\n",
        "\n",
        "            # Create and send an SMS message\n",
        "            message = client.messages.create(\n",
        "                body=f\"Information about {name}:\\nRating: {rating}\\nBed Count: {bed_count}\\nCategory: {category}\",\n",
        "                from_=twilio_phone_number,\n",
        "                to=phone_number\n",
        "            )\n",
        "\n",
        "            print(f\"SMS sent to {name} at {phone_number}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error sending SMS to {name}: {str(e)}\")\n",
        "Try to send an SMS using Twilio. If successful, it prints a confirmation message; otherwise, it prints an error message.\n",
        "\n",
        "\n",
        "Documentation:\n",
        "\n",
        "* Library Imports: The script begins by importing the necessary Python libraries, including csv for handling CSV files, smtplib and ssl for sending emails, MIMEText for creating email messages, and Client for sending SMS messages via Twilio.\n",
        "\n",
        "* Configuration: Set up the configuration details, including email server settings (email_address and email_password) and Twilio credentials (twilio_account_sid, twilio_auth_token, and twilio_phone_number).\n",
        "\n",
        "* CSV File Processing: The script opens and reads a CSV file named 'google_map_business_data.csv', assuming it contains business data with specific columns. It skips the header row using next(reader, None).\n",
        "\n",
        "* Email Sending: For each row in the CSV file, the script constructs an email message with information about the business and attempts to send it using Gmail's SMTP server. Any errors during email sending are caught and reported.\n",
        "\n",
        "* SMS Sending: The script also attempts to send an SMS message to the provided phone number using Twilio. Any errors during SMS sending are caught and reported.\n",
        "\n",
        "Ensure you have the necessary libraries installed (e.g., twilio) and that you've replaced the placeholder values with your actual credentials and CSV file path before running the script."
      ],
      "metadata": {
        "id": "HhbV7efNjoKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import smtplib\n",
        "import ssl\n",
        "\n",
        "from email.mime.text import MIMEText\n",
        "from twilio.rest import Client\n",
        "from email.message import EmailMessage\n",
        "\n",
        "# Define email server settings\n",
        "email_address = 'sender@gmail.com'\n",
        "email_password = 'Generated_password'\n",
        "\n",
        "# Define Twilio credentials\n",
        "twilio_account_sid = 'your_account_sid'\n",
        "twilio_auth_token = 'your_auth_token'\n",
        "twilio_phone_number = 'your_twilio_phone_number'\n",
        "\n",
        "# Open and read the CSV file\n",
        "with open('google_map_business_data.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "\n",
        "    # Skip the header row if it exists\n",
        "    next(reader, None)\n",
        "\n",
        "    for row in reader:\n",
        "        name, rating, bed_count, category, address, phone_number, email, website = row\n",
        "\n",
        "        # Send email\n",
        "        subject = f'Information about {name}'\n",
        "        message = f'Rating: {rating}\\nBed Count: {bed_count}\\nCategory: {category}\\nAddress: {address}\\nWebsite: {website}'\n",
        "        msg = MIMEText(message)\n",
        "        msg['Subject'] = subject\n",
        "        msg['From'] = email_address\n",
        "        msg['To'] = email\n",
        "\n",
        "        try:\n",
        "            # Connect to Gmail's SMTP server\n",
        "            server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "            server.starttls()\n",
        "            server.login(email_address, email_password)\n",
        "\n",
        "            # Send the email\n",
        "            server.sendmail(email_address, email, msg.as_string())\n",
        "            server.quit()\n",
        "\n",
        "            print(f\"Email sent to {name} at {email}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error sending email to {name}: {str(e)}\")\n",
        "\n",
        "        # Send SMS\n",
        "        try:\n",
        "            client = Client(twilio_account_sid, twilio_auth_token)\n",
        "\n",
        "            # Create and send an SMS message\n",
        "            message = client.messages.create(\n",
        "                body=f\"Information about {name}:\\nRating: {rating}\\nBed Count: {bed_count}\\nCategory: {category}\",\n",
        "                from_=twilio_phone_number,\n",
        "                to=phone_number\n",
        "            )\n",
        "\n",
        "            print(f\"SMS sent to {name} at {phone_number}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error sending SMS to {name}: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "4Q5JqU6vb_fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install twilio"
      ],
      "metadata": {
        "id": "ri-KWgmCe9cd"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}